I"Ü<p>ì˜¤ëŠ˜ì€ tripletì„ ì´ìš©í•œ FaceNet ì´í›„ì˜ xxxFace ì‹œë¦¬ì¦ˆì— ëŒ€í•´ ì´ì•¼ê¸°ë¥¼ í•´ë³´ë ¤ê³  í•©ë‹ˆë‹¤. ì–‘ì´ ë§ìŠµë‹ˆë‹¤!<br />
FaceNetì— ëŒ€í•œ ì§€ë‚œ<a href="https://jiryang.github.io/2020/05/23/FaceNet-and-one-shot-learning/">í¬ìŠ¤íŠ¸</a>ì—ì„œ open-set face recognitionì— ëŒ€í•œ ë¬¸ì œë¥¼ ì´ì•¼ê¸°í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ classificationì˜ ê²½ìš° ê° classì— assignëœ dataë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , unseen test dataë¥¼ ì–´ëŠ classì— í• ë‹¹í•  ê²ƒì¸ì§€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ì´ëŸ°ê±¸ closed-set ë¬¸ì œë¼ê³  í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì§€ë‚œ í¬ìŠ¤íŠ¸ì—ì„œ ì–¸ê¸‰í–ˆë˜ face recognitionê³¼ ê°™ì€ ê²½ìš° í•™ìŠµë˜ì§€ ì•Šì€ ì–¼êµ´ì„ ì–´ë–»ê²Œ ì¸ì‹í•  ê²ƒì¸ì§€ì˜ ë¬¸ì œê°€ ìƒê¹ë‹ˆë‹¤. í• ë‹¹í•  classê°€ ì—†ê¸° ë•Œë¬¸ì— FaceNetì—ì„œëŠ” probe faceë¥¼ galleryì— ìˆëŠ” ì–¼êµ´ë“¤ê³¼ ë¹„êµí•˜ê¸° ìœ„í•œ low-dimensional embeddingì„ tripletì„ êµ¬ì„±í•˜ì—¬ í•™ìŠµì‹œì¼°ë˜ ê²ƒì„ ê¸°ì–µí•˜ì‹¤ ê²ƒì…ë‹ˆë‹¤. ì´ëŸ°ê±¸ open-set ë¬¸ì œë¼ê³  í•˜ëŠ”ë°ìš”, ê²°êµ­ open-set face recognitionì€ â€˜real domainì—ì„œ ë‹¤ë¥¸ ì–¼êµ´ì´ë¼ë©´ feature spaceì—ì„œë„ ë‹¤ë¥¸ ì–¼êµ´ì´ë¼ê³  ì¸ì‹í•˜ëŠ”â€™ê²ƒì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ê³ , ë‹¤ë¥´ê²Œ í‘œí˜„í•œë‹¤ë©´ face imageë¥¼ feature spaceë¡œ mappingí•˜ê¸° ìœ„í•œ metricì„ í•™ìŠµí•˜ëŠ” ë¬¸ì œë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ feature spaceëŠ” ì„œë¡œ ë‹¤ë¥¸ ì–¼êµ´ë“¤ì— ëŒ€í•œ êµ¬ë¶„ë ¥ì„ ìµœëŒ€í™”í•´ì•¼ í•  ê²ƒì´ë¯€ë¡œ discriminative marginì„ ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œì˜ mapping metricì„ ë°°ì›Œì•¼ í•©ë‹ˆë‹¤.</p>

<p><img src="https://jiryang.github.io/img/closedset_vs_openset.PNG" alt="Fig1" title="Closed vs Open-Set Face Recognition" width="70%" class="aligncenter" /></p>

<p>Discriminative featureë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë°°ì›Œë³´ìëŠ” ë‘ ê°€ì§€ ì‹œë„ê°€ ìš°ì„  ìˆì—ˆìŠµë‹ˆë‹¤.<br /></p>

<p><strong>Contrastive Loss</strong><br />
Contrastive loss(ë˜ëŠ” pairwise ranking loss)ëŠ” anchor-positive, anchor-negative pairë¥¼ êµ¬ì„±í•´ì„œ ê° ì´ë¯¸ì§€ë¥¼ Siamese networkì— ì§‘ì–´ë„£ì–´ ë‚˜ì˜¨ featureë“¤ì„ ì´ìš©í•˜ì—¬ ë‹¤ìŒì˜ lossë¥¼ ìµœì í™”í•˜ê²Œ ë©ë‹ˆë‹¤:<br />
\(L_{contrasive} = (1-Y) \frac 1 2 (\Vert f(x^i) - f(x^j) \Vert)^2 + Y \frac 1 2{max(0, m - \Vert f(x^i) - f(x^j) \Vert)}^2\)<br />
\(Y\): ë°”ì´ë„ˆë¦¬ label (anchor-positiveì´ë©´ 0, anchor-negativeì´ë©´ 1)
\(f(x^i)\): anchor sample<br />
\(f(x^j)\): positive ë˜ëŠ” negative sample<br /><br />
ìœ„ ì‹ì—ì„œ \(f(x^i) \approx f(x^j)\) ì´ë©´ (anchor-positive setì´ë€ ì–˜ê¸°ê² ì£ ) \(Y\)ì˜ ê°’ì´ 0ì´ ë˜ì–´ì„œ ìœ„ loss ì‹ì˜ ì• í•­ë§Œ ë‚¨ê²Œ ë˜ë©°, anchor-positive ê°„ì˜ ë‹®ì€ ì •ë„ë§Œí¼ \((\Vert f(x^i) - f(x^j) \Vert)^2\)ì˜ ê°’ì´ ì‘ì•„ì ¸ì„œ ìµœì¢… lossëŠ” Mean Squared Error (MSE)ì™€ ê±°ì˜ ê°™ì•„ì§‘ë‹ˆë‹¤. ê·¸ ë°˜ëŒ€ë¡œ anchor-negativeì˜ ê²½ìš°ì—ëŠ” loss ì‹ì˜ ë’· í•­ë§Œ ë‚¨ê²Œ ë˜ê³ , ì´ ë•Œì—ë„ ë§ˆì°¬ê°€ì§€ë¡œ anchor-negativeì˜ ë‹®ì€ ì •ë„ë§Œí¼ \((\Vert f(x^i) - f(x^j) \Vert)^2\)ì˜ ê°’ì´ ì‘ì•„ì§€ê¸´ í•˜ì§€ë§Œ ì°¨ì´ê°€ ì‘ìœ¼ë©´ ì‘ì„ìˆ˜ë¡ lossê°’ì€ \(\frac 1 2 m^2\)ì— ê·¼ì ‘í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ë ‡ê²Œ mì´ anchor-negative pairì— ëŒ€í•œ margin ì—­í• ì„ í•˜ëŠ”ê±°ì£ .</p>

<p><img src="https://jiryang.github.io/img/contrastive_loss_faces.png" alt="Fig2" title="Contrastive Loss" width="70%" class="aligncenter" /></p>

<p><strong><em>FaceNet</em> ì˜ Triplet Loss</strong><br />
Triplet lossì— ëŒ€í•´ì„œëŠ” <a href="https://jiryang.github.io/2020/05/23/FaceNet-and-one-shot-learning/">ì§€ë‚œ í¬ìŠ¤íŠ¸</a>ì—ì„œ ì„¤ëª…ë“œë¦° ë°” ìˆìŠµë‹ˆë‹¤. \(d(A, P) &lt; d(A, N) &lt; d(A, P)+\alpha\) ì¡°ê±´ì„ ì¶”ê°€í•˜ì—¬ì„œ discriminative powerë¥¼ ì¢€ ë” ê°•í™”í•˜ì˜€ì£ .</p>

<p><strong><em>SphereFace</em> ì˜ Angular Loss</strong><br />
Contrastiveì™€ triplet loss ëª¨ë‘ ê¸°ì¡´ì˜ softmax lossë¥¼ ê°œì„ í•˜ì—¬ latent representationì˜ discriminativenessë¥¼ ê°•í™”í•˜ê³  ì´ì— ë”°ë¥¸ marginì„ ì¶”ê°€ë¡œ í•™ìŠµí•˜ì˜€ì§€ë§Œ, ì—¬ì „íˆ Euclidean spaceì—ì„œì˜ distanceë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ì˜ ë©€ê³  ê°€ê¹Œì›€ì„ ê³„ì‚°í•˜ì˜€ë‹¤ëŠ” ì ì€ ë³€í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Center lossë¥¼ ì •ì˜í•œ ë…¼ë¬¸ì—ì„œ MNIST ë°ì´í„°ë¡œ softmax ê¸°ë°˜ classifierë¥¼ í•™ìŠµí•˜ê³  1st, 2nd layer activationì„ plotí•´ ë³¸ ê²°ê³¼ì—ì„œë„ ë‚˜íƒ€ë‚¬ì§€ë§Œ, ì´í›„ CASIA face datasetì„ softmax ë° normalized softmax (modified softmax) ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•œ featureë¥¼ plotí•´ ë³¸ ê²°ê³¼ ì´ featureë“¤ì´ angularí•œ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆë‹¤ëŠ” ê²ƒì„ ê´€ì°°í•˜ê³ , ìì—°íˆ Euclideanì´ ì•„ë‹Œ Euler spaceì—ì„œì˜ distance ê¸°ë°˜ marginì„ ì°¾ì•„ë³´ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.</p>

<p><img src="https://jiryang.github.io/img/mnist_first_layers.PNG" alt="Fig3" title="First Layers Activations of MNIST Classfier" width="70%" class="aligncenter" /></p>

<p>ì•„ë˜ ê·¸ë¦¼ì„ ë³´ì‹œë©´ CASIA face datasetì„ ì‚¬ìš©, (1) classifierë¥¼ softmaxë¡œ í•™ìŠµí•œ featureë¥¼ Euclidean spaceì— plotí•œ ê²ƒ; (2) (1)ì„ Euler spaceì— plot; (3) modified softmax (normalized)ë¡œ í•™ìŠµí•œ featureì˜ Euclidean plot; (4) (3)ì˜ Eulerian plot; (5) angular softmaxë¡œ í•™ìŠµí•œ featureì˜ Euclidean plot; (6) (5)ì˜ Eulerian plot ì„ ì˜ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ê° Euclidean plotì—ëŠ” decision boundaryê°€ x=0 ìœ¼ë¡œ ë‚˜ì™€ìˆê³ , Eulerian plotë“¤ì—ëŠ” angular bisectorê°€ ë³„ë„ë¡œ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. Euclideanë³´ë‹¤ Eulerianì˜ intra-class compactness ë° intra-class dispensionì´ ë” í¬ê³ , ê·¸ ì¤‘ì—ì„œë„ angular softmaxë¥¼ ì‚¬ìš©í•œ (6)ì˜ classê°„ discriminitive powerê°€ ê°€ì¥ í¬ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p><img src="https://jiryang.github.io/img/casia_face_angular_softmax.PNG" alt="Fig4" title="Comparison of Features Learned Using Softmax and A-Softmax Loss" width="70%" class="aligncenter" /></p>

<p>SphereFaceì˜ A-Softmax ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:<br />
\(L_a = \frac 1 N \sum-log(\frac {e^{\Vert x_i \Vert}cos(m \theta, i)} abc)\)</p>

<p><strong><em>CosFace</em> ì˜ Angular Loss</strong><br /></p>

<p><strong><em>ArcFace</em> ì˜ Angular Loss</strong><br /></p>

<p>FaceNetì´ tripletì„ ë§Œë“¤ì–´ì„œ easy-to-hard ìˆœì„œë¡œ í•™ìŠµí•œë‹¤ëŠ” ë¶€ë¶„ì—ì„œ curriculum learningì— ëŒ€í•´ì„œë„ ì ê¹ ì–¸ê¸‰í–ˆì—ˆì§€ìš”.</p>

<p>ì–¼êµ´ ì¸ì‹ ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬</p>

<p>ë…¼ë¬¸ë§í¬: 
<a href="https://arxiv.org/pdf/1704.08063.pdf">SphereFace</a>
<a href="https://arxiv.org/pdf/1801.09414.pdf">CosFace</a>
<a href="https://arxiv.org/pdf/1801.07698.pdf">ArcFace</a>
<a href="https://arxiv.org/pdf/2004.00288.pdf">CurricularFace</a></p>
:ET