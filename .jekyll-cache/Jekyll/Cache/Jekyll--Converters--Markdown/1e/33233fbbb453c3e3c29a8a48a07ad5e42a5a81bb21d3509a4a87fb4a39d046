I"é/<p>ì§€ë‚œ <a href="https://jiryang.github.io/2020/06/08/domain-adaptation/">í¬ìŠ¤íŠ¸</a>ì— ì´ì–´ ì‹œì‘í•©ë‹ˆë‹¤.</p>

<p><em>Discrepancy-based: Architectural</em> <br />
ë˜ë‹¤ë¥¸ discrepancy-based ì ‘ê·¼ë²• ì¤‘ì—ëŠ” ëª¨ë¸ ë„¤íŠ¸ì›Œí¬ì˜ architectureë¥¼ ì´ìš©í•œ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ì•ì„œ ì„¤ëª…í•œ statistical ë°©ì‹ì—ì„œ \(\mathcal{X^S}\)ì™€ \(\mathcal{X^T}\)ë¥¼ í•˜ë‚˜ì˜ ë„¤íŠ¸ì›Œí¬ì— ë„£ì–´ì„œ common feature representationì„ í•™ìŠµí–ˆë˜ ê²ƒê³¼ ë‹¬ë¦¬, ë‘ domain ê°„ì˜ ìœ ì‚¬í•˜ì§€ë§Œ ë‹¤ë¥¸ (ì‚¬ì´ë¹„ì¸ê°€ìš”..) ì ë“¤ì„ ë°˜ì˜í•˜ê¸° ìœ„í•´ two-streamìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì„±í•˜ê³ , ì§ì ‘ì ì¸ weight sharing ëŒ€ì‹  weight regularizer functionì„ ì‚¬ìš©í•˜ì—¬ layer ë³„ weightì˜ relationì„ ê°–ê²Œ í•œ ë°©ì‹ì…ë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì€ ì´ëŸ¬í•œ two-stream networkë¥¼ ì‚¬ìš©í•œ DAì˜ ëŒ€í‘œì ì¸ ì˜ˆì…ë‹ˆë‹¤. Labeled \(\mathcal{X^S}\) (ë° labeled \(\mathcal{X^T}\), if available)ì— ëŒ€í•´ softmax classification lossë¥¼ í•™ìŠµí•˜ê³ , ë‘ domainì˜ discrepancyë¥¼ ì¤„ì´ëŠ” lossë¥¼ í•™ìŠµí•˜ê³ , ë§ì”€ë“œë¦° layer-wise regularization lossë¥¼ í†µí•´ ê° layerì˜ weight ê°’ì— difference bound( )hard ë˜ëŠ” soft)ë¥¼ ë‘ëŠ” ì‹ì…ë‹ˆë‹¤.<br />
ë˜ë‹¤ë¥¸ architectural methodë¡œëŠ” class label ê´€ë ¨ ì •ë³´ëŠ” weight matrixì—, domain ê´€ë ¨ ì •ë³´ëŠ” batch norm (BN)ì˜ statisticsì— ì €ì¥ëœë‹¤ëŠ” ì ì— ì°©ì•ˆí•´ BNì—ì„œ \(\mathcal{D^T}\)ì˜ meanê³¼ stdë¥¼ ì¡°ì •í•˜ë„ë¡ parameterë¥¼ í•™ìŠµì‹œì¼œ domain discrepancyë¥¼ ì¤„ì´ëŠ” Adaptive Batch Normalization (AdaBN) ì´ë¼ëŠ” ë°©ë²•ë„ ìˆìŠµë‹ˆë‹¤.<br />
ë˜í•œ, internal layerì˜ neuron ì¤‘ ì¼ë¶€ëŠ” ë‹¤ì–‘í•œ domainì˜ inputì— activateë˜ëŠ” ê²ƒë„ ìˆëŠ” ë°˜ë©´ ì¼ë¶€ëŠ” íŠ¹ì • domainì— specificí•˜ê²Œ activate ë˜ëŠ” ê²ƒë“¤ì´ ìˆë‹¤ëŠ” ì ì— ì°©ì•ˆí•˜ì—¬, í•˜ë‚˜ì˜ ë„¤íŠ¸ì›Œí¬ì— \(\mathcal{X^S}\)ì™€ \(\mathcal{X^T}\)ë¥¼ ëª¨ë‘ ì…ë ¥í•˜ë©´ì„œ domain-specificí•œ neuronì˜ activationì„ zeroë¡œ masking í•˜ë©´ì„œ domain-generalí•œ feature representationì„ ë”ìš± â€˜ì˜â€™ í•™ìŠµí•˜ë„ë¡ í•˜ëŠ” domain-guided dropoutê³¼ ê°™ì€ ë°©ì‹ë„ architectural approachë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.</p>

<p><img src="https://jiryang.github.io/img/related_weights.PNG" alt="Fig1" title="Two-Stream Architecture with Related Weights" width="80%" class="aligncenter" /></p>

<p><em>Discrepancy-based: Geometric</em> <br />
\(\mathcal{D^S}\)ì™€ \(\mathcal{D^T}\)ì˜ ì°¨ì´ (domain shift)ë¥¼ ì¤„ì—¬ì£¼ëŠ” (ë‘ domain ê°„ì˜ correlationì´ ë†’ì€) ì œ3ì˜ manifoldë¡œ \(\mathcal{X^S}\)ì™€ \(\mathcal{X^T}\)ë¥¼ projectionì‹œí‚¨ í›„ domain-invariant feature representationì„ í•™ìŠµí•˜ê²Œ í•˜ëŠ” ë°©ì‹ì´ geometricí•œ discrepancy-based approachì— ì†í•©ë‹ˆë‹¤. Geometric ë°©ì‹ ì¤‘ì— \(\mathcal{D^S}\)ì™€ \(\mathcal{D^T}\) ì‚¬ì´ì˜ interpolation path ìƒì— ìƒˆë¡œìš´ datasetë“¤ì„ ì¡°í•©í•´ ë§Œë“¤ì–´ë‚´ê³ , ì´ê²ƒë“¤ë¡œë¶€í„° domain-invariantí•œ featureë¥¼ ë½‘ì•„ë‚´ì–´ classificationì— ì´ìš©í•˜ëŠ” Deep Learning for domain adaptation by Interpolating between Domains (DLID)ë¼ëŠ” ë‹¤ì†Œ ì‘ìœ„ì ì¸ ì´ë¦„ì„ ê°€ì§„ ëª¨ë¸ì´ ìˆê¸´ í•œë°, pre-processingì´ ì—„ì²­ë‚œ ê²ƒìœ¼ë¡œ ë³´ì—¬ì„œ ì„¤ëª… ìƒëµí•˜ê³  ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤. í•„ìš”í•˜ì‹  ë¶„ì€ <a href="http://deeplearning.net/wp-content/uploads/2013/03/dlid.pdf">ë§í¬</a> ì°¸ì¡°í•˜ì„¸ìš”.</p>

<p><strong>Adversarial-based</strong><br />
Generator-discriminatorì˜ minimax gameìœ¼ë¡œ í•©ì„± ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” GANì´ í° ì„±ê³µì„ ê±°ë‘ë©´ì„œ, GANì—ì„œ ì°©ì•ˆí•œ DA ë°©ë²•ë¡ ë“¤ë„ ë“±ì¥í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ì„  labeled \(\mathcal{X^S}\)ë¡œ classifierë¥¼ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ê·¸ ë‹¤ìŒ GAN<sub>source</sub>ë¥¼ ì‚¬ìš©í•´ì„œ synthesized source dataë¥¼ ë§Œë“¤ê³ , ì•ì˜ classifierë¡œ synthesized source dataì˜ class labelì„ êµ¬í•©ë‹ˆë‹¤. GAN<sub>source</sub>ì™€ parallelí•œ GAN<sub>target</sub>ì„ domain-invariantí•˜ê²Œ ë§Œë“¤ì–´ ë†“ê³  ë™ì‹œì— synthesized target dataë¥¼ ìƒì„±í•˜ê²Œ í•˜ë©´, ì´ synthesized target dataëŠ” ì•ì˜ synthesized source dataì™€ ë™ì¼í•œ labelì„ ê°€ì§€ë©´ì„œë„ \(\mathcal{X^T}\)ì˜ ë¶„í¬ë¥¼ ë”°ë¥´ëŠ” (\(\mathcal{X^T}\)ì²˜ëŸ¼ ìƒê¸´) outputì´ ë‚˜ì˜¬êº¼ë¼ëŠ” ê²ƒì´ ê¸°ë³¸ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤. ê·¸ ê²°ê³¼ labeled synthesized target dataê°€ ë§Œë“¤ì–´ì§€ëŠ” ì…ˆì´ê¸° ë•Œë¬¸ì—, ì´ê²ƒë“¤ë¡œ classifierë¥¼ í•™ìŠµí•˜ë©´ target classifierê°€ ë§Œë“¤ì–´ì§€ëŠ” ê²ƒì´ì£ . ì¢€ í—·ê°ˆë¦´ ìˆ˜ë„ ìˆëŠ”ë° ì˜ ìƒê°í•´ë³´ë©´ ë§ì´ ë©ë‹ˆë‹¤. ì•„ë˜ëŠ” adversarial-based DAë¥¼ ì¼ë°˜í™”í•œ ê·¸ë¦¼ì…ë‹ˆë‹¤. ì „ì²´ì ì¸ êµ¬ì¡°ëŠ” ìœ ì§€í•œ ìƒíƒœì—ì„œ êµ¬í˜„ì˜ ë””í…Œì¼ì„ ì–´ë–»ê²Œ ê°€ì ¸ê°€ëŠëƒ, íšŒìƒ‰ ë¸”ëŸ­ì˜ ì˜µì…˜ë“¤ì„ ì–´ë–»ê²Œ ì„ íƒí•˜ëŠëƒì— ë”°ë¼ ëª¨ë¸ì´ ë‹¬ë¼ì§„ë‹¤ê³  í•  ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤. íŠ¹íˆ ì²«ë²ˆì§¸ íšŒìƒ‰ ë¸”ëŸ­ì˜ ì„ íƒì§€ì— ë”°ë¼ í•©ì„± ë°ì´í„°ë¥¼ ì‹¤ì œë¡œ ë§Œë“¤ì–´ë‚´ëŠ” ë¶€ë¶„ì´ í¬í•¨ëœ generative ì ‘ê·¼ë²•ê³¼, discriminatorì˜ ë™ì‘ ë°©ì‹ì„ ë³¸ëœ¬ domain discriminatorë¥¼ â€˜ë°˜ëŒ€ë¡œâ€™ í•™ìŠµì‹œì¼œ domain confusionì„ ì¼ìœ¼í‚¤ë„ë¡ í•´ì„œ ëª¨ë¸ì„ domain-invariantí•˜ê²Œ ë§Œë“œëŠ” non-generative ì ‘ê·¼ë²•ìœ¼ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br /></p>

<p><img src="https://jiryang.github.io/img/adversarial_DA.PNG" alt="Fig2" title="Generalized Architecture of Adversarial DA" width="80%" class="aligncenter" /></p>

<p><em>Adversarial-based: Generative</em><br />
Coupled GAN(CoGAN)ì—ì„œëŠ” \(\mathcal{X^S}\)ì™€ \(\mathcal{X^T}\)ë¥¼ í•©ì„±í•˜ëŠ” ë‘ ê°œì˜ paralleí•œ GANì˜ low-level layerë“¤ì˜ weightë¥¼ ê³µìœ ì‹œí‚´ìœ¼ë¡œì¨ higher (í˜¹ì€ deeper) layerë“¤ì´ ë‘ domainì„ ë‹¤ coverí•˜ëŠ” (domain-invariantí•œ) íŠ¹ì„±ì„ í•™ìŠµí•˜ê²Œë” í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.</p>

<p><img src="https://jiryang.github.io/img/cogan.PNG" alt="Fig3" title="Coupled Generative Adversarial Networks" width="80%" class="aligncenter" /></p>

<p><a href="https://arxiv.org/pdf/1603.07442.pdf">Pixel-level domain transfer network</a>ëŠ” (1) Encoder-Decoderë¡œ êµ¬ì„±ëœ domain converter; (2) real-fake discriminator; (3) domain-discriminatorì˜ 3ê°œ ë„¤íŠ¸ì›Œí¬ë¡œ êµ¬ì„±ë˜ì–´ ê°ê°ì´ ë‹¤ìŒê³¼ ê°™ì€ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ì—¬ê¸°ì„œëŠ” ì–´ëŠ ì •ë„ì˜ labeled \(\mathcal{X^T}\)ê°€ í•„ìš”í•©ë‹ˆë‹¤):<br /><br />
(1) Source dataë¥¼ ì…ë ¥ë°›ì•„ target dataë¥¼ í•©ì„±<br />
(2) Real ë˜ëŠ” synthesized target dataë¥¼ ì…ë ¥ë°›ì•„ real/fake binary classification ìˆ˜í–‰<br />
(3) (1)ì˜ sourceì™€ ë™ì¼í•œ classì˜ labeled target data pairë¥¼ ì…ë ¥ë°›ì•„ ë‘ dataì˜ associationì´ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ binary classificationì„ ìˆ˜í–‰<br /><br />
(2)ì˜ ì—­í•  ë•ë¶„ì— (1)ì˜ ë„¤íŠ¸ì›Œí¬ëŠ” <em>realistic fake target data</em> ë¥¼ ë§Œë“¤ê²Œ ë˜ê³ , (3)ì˜ ì—­í•  ë•ë¶„ì— <em>realistic fake target data associated to the source</em> ë¥¼ ë§Œë“¤ê²Œ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.</p>

<p><img src="https://jiryang.github.io/img/pixel_level_domain_transfer.PNG" alt="Fig4" title="Architecture of Pixel-Level Domain Transfer" width="80%" class="aligncenter" /></p>

<p>í•˜ë‚˜ë§Œ ë” ì˜ˆë¥¼ ë“¤ì–´ë³´ì£ . <a href="https://arxiv.org/pdf/1612.05424.pdf">Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks</a> ì—ì„œëŠ” labeled dataê°€ ì¶©ë¶„ì¹˜ ì•Šì•„ renderingí•œ (labelì€ ìë™ìœ¼ë¡œ ë¶™ê² ì£ ?) source dataë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì„œ real source dataì—ë„ generalí•˜ê²Œ ì‚¬ìš©í•˜ë ¤ëŠ” ëª©ì ìœ¼ë¡œ DAë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. Syntheticì´ ë‘ ì¢…ë¥˜ê°€ ë“¤ì–´ê°€ì„œ í—·ê°ˆë¦¬ëŠ”ë°ìš”, ì—¬ê¸°ì„  renderedê°€ \(\mathcal{X^S}\)ì´ê³ , unlabeled realì´ \(\mathcal{X^T}\)ì¸ ì…ˆì…ë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì—ì„œ ë³´ì‹œë©´ (ì—¬ê¸´ renderedë¥¼ syntheticì´ë¼ í‘œí˜„) generator GëŠ” noise vectorì™€ rendered source dataë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ fake source dataë¥¼ ë§Œë“­ë‹ˆë‹¤. Task-specifc classifier TëŠ” rendered source dataì™€ fake source dataë¥¼ ì…ë ¥ë°›ì•„ known class labelë¡œ ë¶„ë¥˜ê°€ ë˜ë„ë¡ í•™ìŠµì„ í•˜ê³ , discriminator DëŠ” real source dataì™€ fake source dataë¥¼ ì…ë ¥ë°›ì•„ real/fakeë¥¼ êµ¬ë¶„í•˜ëŠ” ì—­í• ì„ í•¨ìœ¼ë¡œì¨ fakeë¥¼ realì— ê°€ê¹ê²Œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. 3ê°œ ë„¤íŠ¸ì›Œí¬ë¥¼ í•¨ê»˜ í•™ìŠµì‹œí‚¤ê³  ë‚˜ë©´ rendered dataë¥¼ ì…ë ¥ë°›ì•„; real sourceì™€ ê°€ê¹Œìš°ë©´ì„œë„; rendered dataì˜ classë¡œ ë¶„ë¥˜ë˜ëŠ” fake dataë¥¼ ìƒì„±í•˜ê²Œ ë˜ëŠ”ê±°ì£ .</p>

<p><img src="https://jiryang.github.io/img/unsupervised_pixel_level_DA.PNG" alt="Fig5" title="Architecture of Unsupervised Pixel-Level DA with GAN" width="60%" class="aligncenter" /></p>

<p><em>Adversarial-based: Non-generative</em><br />
Adversarial-based non-generative ë°©ì‹ì˜ DAëŠ” adversarial trainingì˜ discriminatorì˜ ì•„ì´ë””ì–´ë¥¼ ì°¨ìš©í•©ë‹ˆë‹¤. ì˜ˆì‹œ ëª¨ë¸ì„ ë³´ë©´ì„œ ì„¤ëª…í•˜ë„ë¡ í•˜ì§€ìš”. ì•„ë˜ Domain-Adversarial Neural Network(<a href="https://arxiv.org/pdf/1505.07818.pdf">DANN</a>) ë„¤íŠ¸ì›Œí¬ë¥¼ ë³´ì‹œë©´ ì•ë‹¨ì˜ feature extractor (green)ëŠ” ì¼ë°˜ì ì¸ single flow CNNê³¼ ë³„ë‹¤ë¥´ì§€ ì•Šê²Œ ë˜ì–´ìˆìœ¼ë‚˜, ê·¸ ë’¤ì—ëŠ” pathê°€ label predictor (blue)ì™€ domain classifier (red) ë‘˜ë¡œ ê°ˆë¦½ë‹ˆë‹¤. ì´ ë„¤íŠ¸ì›Œí¬ì—ëŠ” \(\mathcal{X^S}\)ì™€ \(\mathcal{X^T}\)ê°€ ëª¨ë‘ ì…ë ¥ë˜ëŠ”ë°ìš”, ì…ë ¥ ë°ì´í„°ì˜ domainì— ë”°ë¼ green, blue, red ëª¨ë“ˆì´ ì„ íƒì ìœ¼ë¡œ ë™ì‘í•˜ê²Œ ë©ë‹ˆë‹¤. ìš°ì„  ì¼ë°˜ì ì¸ classifierì¸ green-blue ì¡°í•©ì€ \(\mathcal{X^S}\)ì¼ ë•Œë§Œ ë™ì‘í•˜ì—¬ class labelì„ ë¶„ë¥˜í•˜ë„ë¡ í•™ìŠµí•˜ê²Œ ë©ë‹ˆë‹¤. Domain classifierì¸ green-red ì¡°í•©ì€ \(\mathcal{X^S}\)ì™€ \(\mathcal{X^T}\)ì˜ ê²½ìš° ëª¨ë‘ ë™ì‘í•˜ì—¬ í•´ë‹¹ inputì´ \(\mathcal{D^S}\)ì—ì„œ ì™”ëŠ”ì§€ \(\mathcal{D^T}\)ì—ì„œ ì™”ëŠ”ì§€ë¥¼ êµ¬ë¶„í•˜ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤. ì´ domain classifierì˜ í•™ìŠµì— DANNì˜ íŠ¹ì§•ì´ ìˆëŠ”ë°ìš”, red ëª¨ë“ˆì€ ì¼ë°˜ì ì¸ backpropagationì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•˜ëŠ” ë°˜ë©´, domain classifier lossê°€ feature extractor ëª¨ë“ˆë¡œ backpropagate ë  ë•Œ gradient reversal layerë¥¼ ê±°ì³ì„œ gradientì˜ ë¶€í˜¸ê°€ ë°”ë€Œê²Œ ë˜ê³ , ì´ ì—­ì „ëœ ê°’ìœ¼ë¡œ ë‚˜ë¨¸ì§€ feature extractor ëª¨ë“ˆì˜ í•™ìŠµì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ì´ëŠ” feature extractorë¡œ í•˜ì—¬ê¸ˆ domainì„ ì˜ êµ¬ë¶„í•˜ì§€ ëª»í•˜ë„ë¡ í•™ìŠµí•˜ê²Œ í•˜ì—¬ì„œ ê²°êµ­ feature extractorì˜ ê²°ê³¼ê°€ domain-invariantí•´ ì§€ëŠ” íš¨ê³¼ë¥¼ ë‚³ìŠµë‹ˆë‹¤. í•™ìŠµì´ ì™„ë£Œë˜ë©´ feature extractorëŠ” label predictorì˜ lossë¡œ ì¸í•´ class êµ¬ë¶„ì´ ë˜ëŠ” featureë¥¼, domain classifierì˜ reversed lossë¡œ ì¸í•´ domainì´ë‘ ìƒê´€ì—†ì´ class êµ¬ë¶„ì´ ë˜ëŠ” featureë¥¼ ë§Œë“¤ê²Œ ë˜ëŠ”ê±°ì£ .</p>

<p><img src="https://jiryang.github.io/img/DANN.PNG" alt="Fig6" title="Domain-Adversarial Neural Network" width="80%" class="aligncenter" /></p>

<p>ë˜ë‹¤ë¥¸ non-generative approachì˜ ì˜ˆë¡œ Adversarial Discriminative Domain Adaptation (<a href="https://arxiv.org/pdf/1702.05464.pdf">ADDA</a>)ê°€ ìˆìŠµë‹ˆë‹¤. ADDAëŠ” DANNê³¼ëŠ” ë‹¬ë¦¬ sourceì™€ target ë³„ë„ì˜ feature extractorë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì—ì„œì™€ ê°™ì´ ì¼ë‹¨ \(\mathcal{X^S}\)ë¡œ classifier pre-trainì„ í•˜ê³ ë‚˜ì„œ, adversarial adaptaionì„ ìœ„í•´ í•™ìŠµëœ classifierì˜ feature extractor ë¶€ë¶„ì„ ë–¼ì„œ domain discriminatorì— ë¶™ì…ë‹ˆë‹¤. Target feature extractorëŠ” learned source feature extractorì˜ weightë¡œ initialize ì‹œí‚¤ê³ , adversarial adaption ê³¼ì •ì—ì„œ ì¶”ê°€ì ìœ¼ë¡œ í•™ìŠµë©ë‹ˆë‹¤. Source ìª½ feature extractorëŠ” ë”ì´ìƒ í•™ìŠµí•˜ì§€ ì•Šê³  weightê°€ ê³ ì •ë©ë‹ˆë‹¤ (ê·¸ë¦¼ì—ì„œ ì ì„ ìœ¼ë¡œ í‘œê¸°ë˜ë©´ weight ê³ ì •ì´ë€ ì˜ë¯¸). Target feature extractorë¥¼ í•™ìŠµí•˜ëŠ” domain discriminatorì˜ adversarial adaptationì€ sourceì™€ target ì—¬ë¶€ë¥¼ invertì‹œì¼œì„œ í•™ìŠµí•˜ì—¬ ì•ì„  DANNì—ì„œì˜ gradient reversal layerë¥¼ ì ìš©í•œ ê²ƒê³¼ ë¹„ìŠ·í•œ íš¨ê³¼ë¥¼ ë‚´ì–´, í•™ìŠµëœ target featureê°€ sourceì™€ domain êµ¬ë¶„ì€ ì˜ ì•ˆë˜ë©´ì„œ classificationì€ ìœ ì‚¬í•˜ê²Œ ë‚˜ì˜¤ëŠ” íŠ¹ì„±ì„ ê°€ì§€ê²Œ ëœë‹¤ëŠ” ì•„ì´ë””ì–´ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ í•™ìŠµëœ target feature extractorë¥¼ ì•ì„œ í•™ìŠµí•œ source classifierì— ë¶™ì—¬ì„œ testë¥¼ í•˜ë©´ unlabeled \(\mathcal{X^T}\)ì„ ê´œì°®ê²Œ classifyí•˜ëŠ” ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ”ê±°ì£ .</p>

<p><img src="https://jiryang.github.io/img/ADDA.PNG" alt="Fig7" title="Adversarial Discriminative Domain Adaptation" width="80%" class="aligncenter" /></p>

<p><strong>Reconstruction-based</strong><br />
Sourceë‚˜ target domain ë°ì´í„°ë¥¼ reconstructí•˜ì—¬ intra-domain specificityì™€ inter-domain indistinguishabilityë¥¼ ë†’ì´ëŠ” ë°©ì‹<br /></p>

<p><em>Reconstruction-based: Encoder-decoder</em><br />
asdfasdfdf</p>

<p><em>Reconstruction-based: Adversarial</em><br />
asdfasdfdf</p>
:ET